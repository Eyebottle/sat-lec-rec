// windows/runner/native_screen_recorder.cpp
// DXGI Desktop Duplication + WASAPI Loopback + FFmpeg íŒŒì´í”„ë¼ì¸ì„ ì‚¬ìš©í•œ í™”ë©´ + ì˜¤ë””ì˜¤ ë…¹í™” êµ¬í˜„
//
// ëª©ì :
//   1. DXGI Desktop Duplicationìœ¼ë¡œ í™”ë©´ ìº¡ì²˜
//   2. WASAPI Loopbackìœ¼ë¡œ ì˜¤ë””ì˜¤ ìº¡ì²˜
//   3. FFmpeg Named Pipeë¡œ Fragmented MP4 ì €ì¥
//
// ì‘ì„±ì¼: 2025-10-22

#include "native_screen_recorder.h"

#include <windows.h>
#include <d3d11.h>
#include <dxgi1_2.h>
#include <mmdeviceapi.h>
#include <audioclient.h>
#include <string>
#include <atomic>
#include <thread>
#include <mutex>
#include <queue>
#include <condition_variable>
#include <cmath>  // Phase 3.1.2: std::sqrt, std::abs
#include <memory>

// DXGI Desktop Duplication API í—¤ë”
#pragma comment(lib, "d3d11.lib")
#pragma comment(lib, "dxgi.lib")

// WASAPI í—¤ë”
#pragma comment(lib, "ole32.lib")
#pragma comment(lib, "winmm.lib")
#include "ffmpeg_pipeline.h"

// ì „ì—­ ìƒíƒœ
static std::atomic<bool> g_is_recording(false);
static std::string g_last_error;
static std::mutex g_error_mutex;
static std::thread g_capture_thread;

// Direct3D11 ê´€ë ¨
static ID3D11Device* g_d3d_device = nullptr;
static ID3D11DeviceContext* g_d3d_context = nullptr;
static ID3D11Texture2D* g_staging_texture = nullptr;
static bool g_com_initialized = false;

// DXGI Desktop Duplication ê´€ë ¨
static IDXGIOutputDuplication* g_dxgi_duplication = nullptr;

// WASAPI ì˜¤ë””ì˜¤ ìº¡ì²˜ ê´€ë ¨
static IMMDevice* g_audio_device = nullptr;
static IAudioClient* g_audio_client = nullptr;
static IAudioCaptureClient* g_audio_capture_client = nullptr;
static WAVEFORMATEX* g_wave_format = nullptr;
static std::thread g_audio_thread;

static std::thread g_encoder_thread;
static std::unique_ptr<FFmpegPipeline> g_ffmpeg_pipeline;

// íƒ€ì„ìŠ¤íƒ¬í”„ ê´€ë¦¬
static LARGE_INTEGER g_recording_start_qpc;
static LARGE_INTEGER g_qpc_frequency;
static LONGLONG g_video_frame_count = 0;
static LONGLONG g_audio_sample_count = 0;
static int g_video_width = 0;
static int g_video_height = 0;
static int g_video_fps = 30;

// í”„ë ˆì„ ë°ì´í„° êµ¬ì¡°
struct FrameData {
    std::vector<uint8_t> pixels;  // BGRA í”½ì…€ ë°ì´í„°
    int width;
    int height;
    uint64_t timestamp;  // QueryPerformanceCounter ê°’
};

// ì˜¤ë””ì˜¤ ìƒ˜í”Œ ë°ì´í„° êµ¬ì¡°
struct AudioSample {
    std::vector<uint8_t> data;     // PCM ì˜¤ë””ì˜¤ ë°ì´í„°
    uint32_t frame_count;          // ì˜¤ë””ì˜¤ í”„ë ˆì„ ìˆ˜
    uint32_t sample_rate;          // ìƒ˜í”Œë ˆì´íŠ¸ (Hz)
    uint16_t channels;             // ì±„ë„ ìˆ˜ (2 = ìŠ¤í…Œë ˆì˜¤)
    uint16_t bits_per_sample;      // ë¹„íŠ¸ ê¹Šì´
    uint64_t timestamp;            // QueryPerformanceCounter ê°’
};

// í”„ë ˆì„ ë²„í¼ í
static std::queue<FrameData> g_frame_queue;
static std::mutex g_queue_mutex;
static std::condition_variable g_queue_cv;
static const size_t MAX_QUEUE_SIZE = 60;  // ìµœëŒ€ 60 í”„ë ˆì„ (ì•½ 2.5ì´ˆ @ 24fps)

// ì˜¤ë””ì˜¤ ë²„í¼ í
static std::queue<AudioSample> g_audio_queue;
static std::mutex g_audio_queue_mutex;
static std::condition_variable g_audio_queue_cv;
static const size_t MAX_AUDIO_QUEUE_SIZE = 100;  // ìµœëŒ€ 100 ìƒ˜í”Œ

// Phase 3.1.2: ì˜¤ë””ì˜¤ ë ˆë²¨ ì¶”ì  (0.0 ~ 1.0)
static std::atomic<float> g_current_audio_level(0.0f);  // RMS ë ˆë²¨
static std::atomic<float> g_peak_audio_level(0.0f);     // Peak ë ˆë²¨

// ì—ëŸ¬ ë©”ì‹œì§€ ì„¤ì • í—¬í¼
static void SetLastError(const std::string& error) {
    std::lock_guard<std::mutex> lock(g_error_mutex);
    g_last_error = error;
}

// Phase 3.1.2: ì˜¤ë””ì˜¤ ë ˆë²¨ ê³„ì‚° í—¬í¼ (Float32 PCM ë°ì´í„°ìš©)
// RMS (Root Mean Square) ê³„ì‚°: ì†Œë¦¬ì˜ "ì—ë„ˆì§€"ë¥¼ ë‚˜íƒ€ëƒ„
// ë°˜í™˜ê°’: 0.0 (ë¬´ìŒ) ~ 1.0 (ìµœëŒ€)
static float CalculateAudioLevel(const BYTE* data, UINT32 frames, UINT16 channels) {
    if (data == nullptr || frames == 0) {
        return 0.0f;
    }

    // WASAPIëŠ” Float32 PCM (-1.0 ~ +1.0) ë°˜í™˜
    const float* samples = reinterpret_cast<const float*>(data);
    UINT32 total_samples = frames * channels;

    // RMS ê³„ì‚°: sqrt(sum(x^2) / n)
    double sum_squares = 0.0;
    float peak = 0.0f;

    for (UINT32 i = 0; i < total_samples; i++) {
        float sample = samples[i];
        sum_squares += sample * sample;

        // Peak ë ˆë²¨ë„ ì¶”ì 
        float abs_sample = std::abs(sample);
        if (abs_sample > peak) {
            peak = abs_sample;
        }
    }

    float rms = static_cast<float>(std::sqrt(sum_squares / total_samples));

    // Peak ë ˆë²¨ ì—…ë°ì´íŠ¸ (atomic)
    g_peak_audio_level.store(peak);

    return rms;
}

// Direct3D11 ë””ë°”ì´ìŠ¤ ìƒì„±
static bool CreateD3D11Device() {
    if (g_d3d_device) {
        return true;  // ì´ë¯¸ ìƒì„±ë¨
    }

    UINT creation_flags = D3D11_CREATE_DEVICE_BGRA_SUPPORT;
#ifdef _DEBUG
    creation_flags |= D3D11_CREATE_DEVICE_DEBUG;
#endif

    D3D_FEATURE_LEVEL feature_levels[] = {
        D3D_FEATURE_LEVEL_11_1,
        D3D_FEATURE_LEVEL_11_0,
        D3D_FEATURE_LEVEL_10_1,
        D3D_FEATURE_LEVEL_10_0
    };

    D3D_FEATURE_LEVEL feature_level;

    HRESULT hr = D3D11CreateDevice(
        nullptr,                        // ê¸°ë³¸ ì–´ëŒ‘í„°
        D3D_DRIVER_TYPE_HARDWARE,       // í•˜ë“œì›¨ì–´ ê°€ì†
        nullptr,
        creation_flags,
        feature_levels,
        ARRAYSIZE(feature_levels),
        D3D11_SDK_VERSION,
        &g_d3d_device,
        &feature_level,
        &g_d3d_context
    );

    if (FAILED(hr)) {
        SetLastError("D3D11 ë””ë°”ì´ìŠ¤ ìƒì„± ì‹¤íŒ¨");
        return false;
    }

    return true;
}

// Direct3D11 ë¦¬ì†ŒìŠ¤ ì •ë¦¬
static void CleanupD3D11() {
    if (g_staging_texture) {
        g_staging_texture->Release();
        g_staging_texture = nullptr;
    }

    if (g_d3d_context) {
        g_d3d_context->Release();
        g_d3d_context = nullptr;
    }

    if (g_d3d_device) {
        g_d3d_device->Release();
        g_d3d_device = nullptr;
    }
}

// DXGI Desktop Duplication ì´ˆê¸°í™”
static bool InitializeDXGIDuplication() {
    HRESULT hr;

    // 1. DXGI ì–´ëŒ‘í„° ê°€ì ¸ì˜¤ê¸°
    printf("[C++] 1/4: DXGI ì–´ëŒ‘í„° ê°€ì ¸ì˜¤ê¸°...\n");
    fflush(stdout);

    IDXGIDevice* dxgi_device = nullptr;
    hr = g_d3d_device->QueryInterface(__uuidof(IDXGIDevice), (void**)&dxgi_device);
    if (FAILED(hr)) {
        printf("[C++] âŒ DXGI ë””ë°”ì´ìŠ¤ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨ (HRESULT: 0x%08X)\n", hr);
        fflush(stdout);
        SetLastError("DXGI ë””ë°”ì´ìŠ¤ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨");
        return false;
    }

    IDXGIAdapter* dxgi_adapter = nullptr;
    hr = dxgi_device->GetAdapter(&dxgi_adapter);
    dxgi_device->Release();
    if (FAILED(hr)) {
        printf("[C++] âŒ DXGI ì–´ëŒ‘í„° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨ (HRESULT: 0x%08X)\n", hr);
        fflush(stdout);
        SetLastError("DXGI ì–´ëŒ‘í„° ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨");
        return false;
    }

    // 2. ì£¼ ì¶œë ¥(ëª¨ë‹ˆí„°) ê°€ì ¸ì˜¤ê¸°
    printf("[C++] 2/4: ì£¼ ëª¨ë‹ˆí„° ì¶œë ¥ ê°€ì ¸ì˜¤ê¸°...\n");
    fflush(stdout);

    IDXGIOutput* dxgi_output = nullptr;
    hr = dxgi_adapter->EnumOutputs(0, &dxgi_output);  // ì²« ë²ˆì§¸ ëª¨ë‹ˆí„°
    dxgi_adapter->Release();
    if (FAILED(hr)) {
        printf("[C++] âŒ DXGI ì¶œë ¥ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨ (HRESULT: 0x%08X)\n", hr);
        fflush(stdout);
        SetLastError("DXGI ì¶œë ¥ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨");
        return false;
    }

    // 3. IDXGIOutput1ë¡œ ë³€í™˜
    printf("[C++] 3/4: IDXGIOutput1 ë³€í™˜...\n");
    fflush(stdout);

    IDXGIOutput1* dxgi_output1 = nullptr;
    hr = dxgi_output->QueryInterface(__uuidof(IDXGIOutput1), (void**)&dxgi_output1);
    dxgi_output->Release();
    if (FAILED(hr)) {
        printf("[C++] âŒ IDXGIOutput1 ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨ (HRESULT: 0x%08X)\n", hr);
        fflush(stdout);
        SetLastError("IDXGIOutput1 ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨");
        return false;
    }

    // 4. Desktop Duplication ìƒì„±
    printf("[C++] 4/4: Desktop Duplication ìƒì„±...\n");
    fflush(stdout);

    hr = dxgi_output1->DuplicateOutput(g_d3d_device, &g_dxgi_duplication);
    dxgi_output1->Release();
    if (FAILED(hr)) {
        printf("[C++] âŒ Desktop Duplication ìƒì„± ì‹¤íŒ¨ (HRESULT: 0x%08X)\n", hr);
        fflush(stdout);
        SetLastError("Desktop Duplication ìƒì„± ì‹¤íŒ¨");
        return false;
    }

    printf("[C++] âœ… Desktop Duplication ìƒì„± ì„±ê³µ\n");
    fflush(stdout);

    return true;
}

// DXGI Duplication ë¦¬ì†ŒìŠ¤ ì •ë¦¬
static void CleanupDXGIDuplication() {
    if (g_dxgi_duplication) {
        g_dxgi_duplication->Release();
        g_dxgi_duplication = nullptr;
    }
}

// WASAPI ì´ˆê¸°í™”
static bool InitializeWASAPI() {
    HRESULT hr;

    printf("[C++] WASAPI ì´ˆê¸°í™” ì‹œì‘...\n");
    fflush(stdout);

    // 1. IMMDeviceEnumerator ìƒì„±
    printf("[C++] 1/4: IMMDeviceEnumerator ìƒì„±...\n");
    fflush(stdout);

    IMMDeviceEnumerator* enumerator = nullptr;
    hr = CoCreateInstance(
        __uuidof(MMDeviceEnumerator),
        nullptr,
        CLSCTX_ALL,
        __uuidof(IMMDeviceEnumerator),
        (void**)&enumerator
    );
    if (FAILED(hr)) {
        printf("[C++] âŒ IMMDeviceEnumerator ìƒì„± ì‹¤íŒ¨ (HRESULT: 0x%08X)\n", hr);
        fflush(stdout);
        SetLastError("IMMDeviceEnumerator ìƒì„± ì‹¤íŒ¨");
        return false;
    }

    // 2. ê¸°ë³¸ ë Œë” ë””ë°”ì´ìŠ¤ ê°€ì ¸ì˜¤ê¸° (ìŠ¤í”¼ì»¤)
    printf("[C++] 2/4: ê¸°ë³¸ ì˜¤ë””ì˜¤ ì¥ì¹˜ ê°€ì ¸ì˜¤ê¸°...\n");
    fflush(stdout);

    hr = enumerator->GetDefaultAudioEndpoint(
        eRender,      // ë Œë” (ì¶œë ¥) ì¥ì¹˜
        eConsole,     // ì½˜ì†” ì—­í• 
        &g_audio_device
    );
    enumerator->Release();

    if (FAILED(hr)) {
        printf("[C++] âŒ ê¸°ë³¸ ì˜¤ë””ì˜¤ ì¥ì¹˜ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨ (HRESULT: 0x%08X)\n", hr);
        fflush(stdout);
        SetLastError("ê¸°ë³¸ ì˜¤ë””ì˜¤ ì¥ì¹˜ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨");
        return false;
    }

    // 3. IAudioClient ìƒì„±
    printf("[C++] 3/4: IAudioClient ìƒì„±...\n");
    fflush(stdout);

    hr = g_audio_device->Activate(
        __uuidof(IAudioClient),
        CLSCTX_ALL,
        nullptr,
        (void**)&g_audio_client
    );
    if (FAILED(hr)) {
        printf("[C++] âŒ IAudioClient ìƒì„± ì‹¤íŒ¨ (HRESULT: 0x%08X)\n", hr);
        fflush(stdout);
        SetLastError("IAudioClient ìƒì„± ì‹¤íŒ¨");
        return false;
    }

    // 4. ì˜¤ë””ì˜¤ í¬ë§· ê°€ì ¸ì˜¤ê¸°
    printf("[C++] 4/4: ì˜¤ë””ì˜¤ í¬ë§· ê°€ì ¸ì˜¤ê¸°...\n");
    fflush(stdout);

    hr = g_audio_client->GetMixFormat(&g_wave_format);
    if (FAILED(hr)) {
        printf("[C++] âŒ ì˜¤ë””ì˜¤ í¬ë§· ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨ (HRESULT: 0x%08X)\n", hr);
        fflush(stdout);
        SetLastError("ì˜¤ë””ì˜¤ í¬ë§· ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨");
        return false;
    }

    printf("[C++] âœ… ì˜¤ë””ì˜¤ í¬ë§·: %d Hz, %d channels, %d bits\n",
           g_wave_format->nSamplesPerSec,
           g_wave_format->nChannels,
           g_wave_format->wBitsPerSample);
    fflush(stdout);

    // 5. Loopback ëª¨ë“œë¡œ ì´ˆê¸°í™”
    REFERENCE_TIME buffer_duration = 1000 * 10000;  // 100ms in 100-nanosecond units

    hr = g_audio_client->Initialize(
        AUDCLNT_SHAREMODE_SHARED,        // Shared ëª¨ë“œ
        AUDCLNT_STREAMFLAGS_LOOPBACK,    // Loopback í”Œë˜ê·¸ (í•µì‹¬!)
        buffer_duration,
        0,
        g_wave_format,
        nullptr
    );
    if (FAILED(hr)) {
        printf("[C++] âŒ AudioClient ì´ˆê¸°í™” ì‹¤íŒ¨ (HRESULT: 0x%08X)\n", hr);
        fflush(stdout);
        SetLastError("AudioClient ì´ˆê¸°í™” ì‹¤íŒ¨");
        return false;
    }

    // 6. IAudioCaptureClient ê°€ì ¸ì˜¤ê¸°
    hr = g_audio_client->GetService(
        __uuidof(IAudioCaptureClient),
        (void**)&g_audio_capture_client
    );
    if (FAILED(hr)) {
        printf("[C++] âŒ IAudioCaptureClient ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨ (HRESULT: 0x%08X)\n", hr);
        fflush(stdout);
        SetLastError("IAudioCaptureClient ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨");
        return false;
    }

    // 7. ìº¡ì²˜ ì‹œì‘
    hr = g_audio_client->Start();
    if (FAILED(hr)) {
        printf("[C++] âŒ ì˜¤ë””ì˜¤ ìº¡ì²˜ ì‹œì‘ ì‹¤íŒ¨ (HRESULT: 0x%08X)\n", hr);
        fflush(stdout);
        SetLastError("ì˜¤ë””ì˜¤ ìº¡ì²˜ ì‹œì‘ ì‹¤íŒ¨");
        return false;
    }

    printf("[C++] âœ… WASAPI ì´ˆê¸°í™” ì™„ë£Œ (Loopback ëª¨ë“œ)\n");
    fflush(stdout);

    return true;
}

// WASAPI ë¦¬ì†ŒìŠ¤ ì •ë¦¬
static void CleanupWASAPI() {
    printf("[C++] WASAPI ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹œì‘...\n");
    fflush(stdout);

    if (g_audio_client) {
        g_audio_client->Stop();
    }

    if (g_audio_capture_client) {
        g_audio_capture_client->Release();
        g_audio_capture_client = nullptr;
    }

    if (g_audio_client) {
        g_audio_client->Release();
        g_audio_client = nullptr;
    }

    if (g_audio_device) {
        g_audio_device->Release();
        g_audio_device = nullptr;
    }

    if (g_wave_format) {
        CoTaskMemFree(g_wave_format);
        g_wave_format = nullptr;
    }

    printf("[C++] âœ… WASAPI ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ\n");
    fflush(stdout);
}

//==============================================================================
// FFmpeg íŒŒì´í”„ë¼ì¸ ë³´ì¡° í•¨ìˆ˜
//==============================================================================

// ì…ë ¥: ì—†ìŒ
// ì¶œë ¥: íƒ€ì„ìŠ¤íƒ¬í”„ì™€ ì¹´ìš´í„° ì´ˆê¸°í™”
// ì˜ˆì™¸: ì—†ìŒ
static void ResetRecordingStats() {
    QueryPerformanceFrequency(&g_qpc_frequency);
    QueryPerformanceCounter(&g_recording_start_qpc);
    g_video_frame_count = 0;
    g_audio_sample_count = 0;
}

// ì…ë ¥: ì—†ìŒ (í ë‚´ë¶€ ë°ì´í„° ì‚¬ìš©)
// ì¶œë ¥: ë¹„ë””ì˜¤ í”„ë ˆì„ì„ FFmpeg íŒŒì´í”„ì— ì „ì†¡í–ˆëŠ”ì§€ ì—¬ë¶€
// ì˜ˆì™¸: íŒŒì´í”„ ì˜¤ë¥˜ ì‹œ false, last_error ê°±ì‹ 
static bool ProcessNextVideoFrame() {
    std::unique_lock<std::mutex> lock(g_queue_mutex);
    if (g_frame_queue.empty()) {
        return false;
    }

    FrameData frame = std::move(g_frame_queue.front());
    g_frame_queue.pop();
    lock.unlock();

    if (!g_ffmpeg_pipeline || !g_ffmpeg_pipeline->IsRunning()) {
        SetLastError("FFmpeg íŒŒì´í”„ë¼ì¸ì´ ì‹¤í–‰ ì¤‘ì´ ì•„ë‹™ë‹ˆë‹¤.");
        return false;
    }

    if (!g_ffmpeg_pipeline->WriteVideo(frame.pixels.data(), frame.pixels.size())) {
        SetLastError(g_ffmpeg_pipeline->last_error());
        return false;
    }

    g_video_frame_count++;
    if (g_video_frame_count == 1 || g_video_frame_count % 120 == 0) {
        printf("[C++] ë¹„ë””ì˜¤ í”„ë ˆì„ #%lld ì „ì†¡ ì™„ë£Œ\n", g_video_frame_count);
        fflush(stdout);
    }
    return true;
}

// ì…ë ¥: ì—†ìŒ (í ë‚´ë¶€ ë°ì´í„° ì‚¬ìš©)
// ì¶œë ¥: ì˜¤ë””ì˜¤ ìƒ˜í”Œì„ FFmpeg íŒŒì´í”„ì— ì „ì†¡í–ˆëŠ”ì§€ ì—¬ë¶€
// ì˜ˆì™¸: íŒŒì´í”„ ì˜¤ë¥˜ ì‹œ false, last_error ê°±ì‹ 
static bool ProcessNextAudioSample() {
    static int audio_packet_count = 0;
    static int audio_debug_log_count = 0;

    std::unique_lock<std::mutex> lock(g_audio_queue_mutex);
    if (g_audio_queue.empty()) {
        return false;
    }

    size_t queue_size_before_pop = g_audio_queue.size();
    AudioSample audio = std::move(g_audio_queue.front());
    g_audio_queue.pop();
    lock.unlock();

    size_t queue_remaining = queue_size_before_pop > 0 ? queue_size_before_pop - 1 : 0;

    if (!g_ffmpeg_pipeline || !g_ffmpeg_pipeline->IsRunning()) {
        SetLastError("FFmpeg íŒŒì´í”„ë¼ì¸ì´ ì‹¤í–‰ ì¤‘ì´ ì•„ë‹™ë‹ˆë‹¤.");
        return false;
    }

    int next_packet_index = audio_packet_count + 1;
    double elapsed_ms = 0.0;
    if (g_qpc_frequency.QuadPart > 0) {
        long double start_qpc = static_cast<long double>(g_recording_start_qpc.QuadPart);
        long double audio_qpc = static_cast<long double>(audio.timestamp);
        long double delta = audio_qpc - start_qpc;
        if (delta < 0.0L) {
            delta = 0.0L;
        }
        elapsed_ms = static_cast<double>(delta * 1000.0L /
                                         static_cast<long double>(g_qpc_frequency.QuadPart));
    }

    if (audio_debug_log_count < 5) {
        printf("[C++] ì˜¤ë””ì˜¤ íŒ¨í‚· #%d ì¤€ë¹„ - ë°”ì´íŠ¸:%llu, í”„ë ˆì„:%u, ì”ì—¬ í:%llu, ê²½ê³¼:%.2fms\n",
               next_packet_index,
               static_cast<unsigned long long>(audio.data.size()),
               audio.frame_count,
               static_cast<unsigned long long>(queue_remaining),
               elapsed_ms);
        fflush(stdout);
        audio_debug_log_count++;
    }

    if (!g_ffmpeg_pipeline->WriteAudio(audio.data.data(), audio.data.size())) {
        const std::string pipeline_error = g_ffmpeg_pipeline->last_error();
        printf("[C++] âŒ ì˜¤ë””ì˜¤ íŒ¨í‚· #%d íŒŒì´í”„ ì „ì†¡ ì‹¤íŒ¨\n", next_packet_index);
        printf("[C++]    ì—ëŸ¬ ë©”ì‹œì§€: %s\n", pipeline_error.c_str());
        printf("[C++]    ë°ì´í„° í¬ê¸°: %llu bytes\n", static_cast<unsigned long long>(audio.data.size()));
        printf("[C++]    í”„ë ˆì„ ìˆ˜: %u\n", audio.frame_count);
        printf("[C++]    íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì¤‘: %s\n", g_ffmpeg_pipeline->IsRunning() ? "ì˜ˆ" : "ì•„ë‹ˆì˜¤");
        fflush(stdout);
        SetLastError(pipeline_error.empty() ? "ì˜¤ë””ì˜¤ íŒŒì´í”„ ì „ì†¡ ì‹¤íŒ¨" : pipeline_error);
        return false;
    }

    g_audio_sample_count += audio.frame_count;

    audio_packet_count++;
    if (audio_packet_count == 1 || audio_packet_count % 100 == 0) {
        printf("[C++] ì˜¤ë””ì˜¤ íŒ¨í‚· #%d ì „ì†¡ ì™„ë£Œ\n", audio_packet_count);
        fflush(stdout);
    }

    return true;
}

// ì…ë ¥: ì—†ìŒ
// ì¶œë ¥: ì—†ìŒ (íŒŒì´í”„ì— ë°ì´í„° ì§€ì† ì „ì†¡)
// ì˜ˆì™¸: íŒŒì´í”„ ì˜¤ë¥˜ ì‹œ last_error ê°±ì‹  í›„ ë£¨í”„ ì¢…ë£Œ
static void EncoderThreadFunc() {
    printf("[C++] FFmpeg íŒŒì´í”„ ì¸ì½”ë” ìŠ¤ë ˆë“œ ì‹œì‘...\n");
    fflush(stdout);

    ResetRecordingStats();

    while (g_is_recording || !g_frame_queue.empty() || !g_audio_queue.empty()) {
        bool processed = false;
        processed |= ProcessNextVideoFrame();
        processed |= ProcessNextAudioSample();

        if (!processed) {
            Sleep(2);
        }
    }

    while (ProcessNextVideoFrame() || ProcessNextAudioSample()) {
        // ì”ì—¬ ë°ì´í„° ë¹„ìš°ê¸°
    }

    printf("[C++] FFmpeg íŒŒì´í”„ ì¸ì½”ë” ìŠ¤ë ˆë“œ ì¢…ë£Œ\n");
    fflush(stdout);
}

// í”„ë ˆì„ íì— ì¶”ê°€ (ë‚˜ì¤‘ì— FrameArrivedì—ì„œ ì‚¬ìš©)
[[maybe_unused]] static void EnqueueFrame(const FrameData& frame) {
    std::lock_guard<std::mutex> lock(g_queue_mutex);

    if (g_frame_queue.size() >= MAX_QUEUE_SIZE) {
        // íê°€ ê°€ë“ ì°¬ ê²½ìš°: ê°€ì¥ ì˜¤ë˜ëœ í”„ë ˆì„ ë²„ë¦¼
        g_frame_queue.pop();
    }

    g_frame_queue.push(frame);
    g_queue_cv.notify_one();
}

// í”„ë ˆì„ íì—ì„œ ê°€ì ¸ì˜¤ê¸° (ë‚˜ì¤‘ì— ì¸ì½”ë” ìŠ¤ë ˆë“œì—ì„œ ì‚¬ìš©)
[[maybe_unused]] static FrameData DequeueFrame() {
    std::unique_lock<std::mutex> lock(g_queue_mutex);
    g_queue_cv.wait(lock, [] {
        return !g_frame_queue.empty() || !g_is_recording;
    });

    if (g_frame_queue.empty()) return FrameData{};

    FrameData frame = g_frame_queue.front();
    g_frame_queue.pop();
    return frame;
}

// ì˜¤ë””ì˜¤ ìƒ˜í”Œ íì— ì¶”ê°€
[[maybe_unused]] static void EnqueueAudioSample(const AudioSample& sample) {
    std::lock_guard<std::mutex> lock(g_audio_queue_mutex);

    if (g_audio_queue.size() >= MAX_AUDIO_QUEUE_SIZE) {
        // íê°€ ê°€ë“ ì°¬ ê²½ìš°: ê°€ì¥ ì˜¤ë˜ëœ ìƒ˜í”Œ ë²„ë¦¼
        g_audio_queue.pop();
    }

    g_audio_queue.push(sample);
    g_audio_queue_cv.notify_one();
}

// ì˜¤ë””ì˜¤ ìƒ˜í”Œ íì—ì„œ ê°€ì ¸ì˜¤ê¸°
[[maybe_unused]] static AudioSample DequeueAudioSample() {
    std::unique_lock<std::mutex> lock(g_audio_queue_mutex);
    g_audio_queue_cv.wait(lock, [] {
        return !g_audio_queue.empty() || !g_is_recording;
    });

    if (g_audio_queue.empty()) return AudioSample{};

    AudioSample sample = g_audio_queue.front();
    g_audio_queue.pop();
    return sample;
}

// ì˜¤ë””ì˜¤ ìº¡ì²˜ ë£¨í”„ (ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰)
static void AudioCaptureThreadFunc() {
    printf("[C++] ì˜¤ë””ì˜¤ ìº¡ì²˜ ìŠ¤ë ˆë“œ ì‹œì‘...\n");
    fflush(stdout);

    HRESULT hr;
    int sample_count = 0;

    while (g_is_recording) {
        // ì‚¬ìš© ê°€ëŠ¥í•œ íŒ¨í‚· í™•ì¸
        UINT32 packet_length = 0;
        hr = g_audio_capture_client->GetNextPacketSize(&packet_length);
        if (FAILED(hr)) {
            printf("[C++] âŒ GetNextPacketSize ì‹¤íŒ¨ (HRESULT: 0x%08X)\n", hr);
            fflush(stdout);
            break;
        }

        while (packet_length != 0) {
            // ì˜¤ë””ì˜¤ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            BYTE* data = nullptr;
            UINT32 frames_available = 0;
            DWORD flags = 0;

            hr = g_audio_capture_client->GetBuffer(
                &data,
                &frames_available,
                &flags,
                nullptr,
                nullptr
            );

            if (FAILED(hr)) {
                printf("[C++] âŒ GetBuffer ì‹¤íŒ¨ (HRESULT: 0x%08X)\n", hr);
                fflush(stdout);
                break;
            }

            // ë¬´ìŒ í”Œë˜ê·¸ í™•ì¸
            if (!(flags & AUDCLNT_BUFFERFLAGS_SILENT)) {
                // Phase 3.1.2: ì˜¤ë””ì˜¤ ë ˆë²¨ ê³„ì‚° ë° ì—…ë°ì´íŠ¸
                float audio_level = CalculateAudioLevel(data, frames_available, g_wave_format->nChannels);
                g_current_audio_level.store(audio_level);

                // ì˜¤ë””ì˜¤ ìƒ˜í”Œ ìƒì„±
                AudioSample sample;
                sample.frame_count = frames_available;
                sample.sample_rate = g_wave_format->nSamplesPerSec;
                sample.channels = g_wave_format->nChannels;
                sample.bits_per_sample = g_wave_format->wBitsPerSample;

                // ë°ì´í„° í¬ê¸° ê³„ì‚° ë° ë³µì‚¬
                UINT32 data_size = frames_available * g_wave_format->nBlockAlign;
                sample.data.resize(data_size);
                memcpy(sample.data.data(), data, data_size);

                // íƒ€ì„ìŠ¤íƒ¬í”„ ì„¤ì •
                LARGE_INTEGER qpc;
                QueryPerformanceCounter(&qpc);
                sample.timestamp = qpc.QuadPart;

                // íì— ì¶”ê°€
                EnqueueAudioSample(sample);

                sample_count++;
                if (sample_count == 1) {
                    printf("[C++] ğŸ¤ ì²« ë²ˆì§¸ ì˜¤ë””ì˜¤ ìƒ˜í”Œ ìº¡ì²˜ ì„±ê³µ! (%d frames)\n", frames_available);
                    fflush(stdout);
                }
                if (sample_count % 100 == 0) {
                    printf("[C++] ğŸ“Š ì˜¤ë””ì˜¤ ìƒ˜í”Œ: %dê°œ ìº¡ì²˜ë¨\n", sample_count);
                    fflush(stdout);
                }
            } else {
                // Phase 3.1.2: ë¬´ìŒì¼ ë•Œ ë ˆë²¨ 0ìœ¼ë¡œ ì„¤ì •
                g_current_audio_level.store(0.0f);
                g_peak_audio_level.store(0.0f);
            }

            // ë²„í¼ í•´ì œ
            g_audio_capture_client->ReleaseBuffer(frames_available);

            // ë‹¤ìŒ íŒ¨í‚· í™•ì¸
            g_audio_capture_client->GetNextPacketSize(&packet_length);
        }

        // 10ms ëŒ€ê¸° (CPU ì ˆì•½)
        Sleep(10);
    }

    printf("[C++] ì˜¤ë””ì˜¤ ìº¡ì²˜ ìŠ¤ë ˆë“œ ì¢…ë£Œ, ì´ %dê°œ ìƒ˜í”Œ ìº¡ì²˜ë¨\n", sample_count);
    fflush(stdout);
}

// í”„ë ˆì„ ìº¡ì²˜ (DXGI Desktop Duplication)
static bool CaptureFrame() {
    HRESULT hr;
    DXGI_OUTDUPL_FRAME_INFO frame_info;
    IDXGIResource* desktop_resource = nullptr;

    // 1. í”„ë ˆì„ ê°€ì ¸ì˜¤ê¸° (íƒ€ì„ì•„ì›ƒ 100ms)
    hr = g_dxgi_duplication->AcquireNextFrame(100, &frame_info, &desktop_resource);
    if (hr == DXGI_ERROR_WAIT_TIMEOUT) {
        return true;  // íƒ€ì„ì•„ì›ƒì€ ì •ìƒ (ìƒˆ í”„ë ˆì„ ì—†ìŒ)
    }
    if (FAILED(hr)) {
        SetLastError("í”„ë ˆì„ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨");
        return false;
    }

    // 2. ID3D11Texture2Dë¡œ ë³€í™˜
    ID3D11Texture2D* desktop_texture = nullptr;
    hr = desktop_resource->QueryInterface(__uuidof(ID3D11Texture2D), (void**)&desktop_texture);
    desktop_resource->Release();
    if (FAILED(hr)) {
        g_dxgi_duplication->ReleaseFrame();
        SetLastError("Texture ë³€í™˜ ì‹¤íŒ¨");
        return false;
    }

    // 3. Staging Textureë¡œ ë³µì‚¬ (GPU â†’ CPU)
    D3D11_TEXTURE2D_DESC desc;
    desktop_texture->GetDesc(&desc);

    if (!g_staging_texture) {
        // Staging Texture ìƒì„± (ìµœì´ˆ 1íšŒ)
        desc.Usage = D3D11_USAGE_STAGING;
        desc.BindFlags = 0;
        desc.CPUAccessFlags = D3D11_CPU_ACCESS_READ;
        desc.MiscFlags = 0;
        g_d3d_device->CreateTexture2D(&desc, nullptr, &g_staging_texture);
    }

    g_d3d_context->CopyResource(g_staging_texture, desktop_texture);
    desktop_texture->Release();

    // 4. CPU ë©”ëª¨ë¦¬ë¡œ ì½ê¸°
    D3D11_MAPPED_SUBRESOURCE mapped;
    hr = g_d3d_context->Map(g_staging_texture, 0, D3D11_MAP_READ, 0, &mapped);
    if (SUCCEEDED(hr)) {
        FrameData frame;
        frame.width = desc.Width;
        frame.height = desc.Height;

        // í”½ì…€ ë°ì´í„° ë³µì‚¬ (í–‰ ë‹¨ìœ„)
        size_t pixel_count = desc.Width * desc.Height * 4;  // BGRA
        frame.pixels.resize(pixel_count);

        uint8_t* src = (uint8_t*)mapped.pData;
        uint8_t* dst = frame.pixels.data();

        for (UINT y = 0; y < desc.Height; y++) {
            memcpy(dst + y * desc.Width * 4, src + y * mapped.RowPitch, desc.Width * 4);
        }

        g_d3d_context->Unmap(g_staging_texture, 0);

        // íƒ€ì„ìŠ¤íƒ¬í”„ ì„¤ì •
        LARGE_INTEGER qpc;
        QueryPerformanceCounter(&qpc);
        frame.timestamp = qpc.QuadPart;

        // í”„ë ˆì„ íì— ì¶”ê°€
        EnqueueFrame(frame);
    }

    // 5. í”„ë ˆì„ í•´ì œ
    g_dxgi_duplication->ReleaseFrame();

    return true;
}

// ë…¹í™” ìŠ¤ë ˆë“œ í•¨ìˆ˜
static void CaptureThreadFunc(
    std::string output_path,
    int32_t width,
    int32_t height,
    int32_t fps
) {
    // DXGI Desktop Duplication ì´ˆê¸°í™”
    printf("[C++] DXGI Desktop Duplication ì´ˆê¸°í™” ì‹œì‘...\n");
    fflush(stdout);

    if (!InitializeDXGIDuplication()) {
        printf("[C++] âŒ Desktop Duplication ì´ˆê¸°í™” ì‹¤íŒ¨\n");
        fflush(stdout);
        SetLastError("Desktop Duplication ì´ˆê¸°í™” ì‹¤íŒ¨");
        g_is_recording = false;
        return;
    }

    printf("[C++] âœ… DXGI Desktop Duplication ì´ˆê¸°í™” ì™„ë£Œ\n");
    fflush(stdout);

    // WASAPI Loopback ì´ˆê¸°í™”
    if (!InitializeWASAPI()) {
        printf("[C++] âŒ WASAPI ì´ˆê¸°í™” ì‹¤íŒ¨\n");
        fflush(stdout);
        SetLastError("WASAPI ì´ˆê¸°í™” ì‹¤íŒ¨");
        CleanupDXGIDuplication();
        g_is_recording = false;
        return;
    }

    // ì˜¤ë””ì˜¤ ìº¡ì²˜ ìŠ¤ë ˆë“œ ì‹œì‘
    g_audio_thread = std::thread(AudioCaptureThreadFunc);

    // ì¶œë ¥ íŒŒì¼ ê²½ë¡œë¥¼ wchar_të¡œ ë³€í™˜ (UTF-8 â†’ UTF-16)
    int wide_length = MultiByteToWideChar(CP_UTF8, 0, output_path.c_str(), -1, nullptr, 0);
    if (wide_length <= 1) {
        printf("[C++] âŒ ì¶œë ¥ ê²½ë¡œ UTF-16 ë³€í™˜ ì‹¤íŒ¨\n");
        fflush(stdout);
        CleanupWASAPI();
        CleanupDXGIDuplication();
        if (g_audio_thread.joinable()) g_audio_thread.join();
        g_is_recording = false;
        return;
    }

    std::wstring w_output_path(wide_length - 1, 0);
    MultiByteToWideChar(CP_UTF8, 0, output_path.c_str(), -1, w_output_path.data(), wide_length);

    // FFmpeg íŒŒì´í”„ë¼ì¸ ì¤€ë¹„
    g_video_width = width;
    g_video_height = height;
    g_video_fps = fps;

    FFmpegLaunchConfig pipeline_config;
    pipeline_config.output_path = w_output_path;
    pipeline_config.video_width = width;
    pipeline_config.video_height = height;
    pipeline_config.video_fps = fps;
    pipeline_config.audio_sample_rate = g_wave_format->nSamplesPerSec;
    pipeline_config.audio_channels = g_wave_format->nChannels;
    pipeline_config.enable_fragmented_mp4 = true;
    pipeline_config.video_only = true;  // Hybrid ë°©ì‹: Videoë§Œ Named Pipeë¡œ ì¸ì½”ë”©

    try {
        g_ffmpeg_pipeline = std::make_unique<FFmpegPipeline>();
        if (!g_ffmpeg_pipeline->Start(pipeline_config)) {
            printf("[C++] âŒ FFmpeg íŒŒì´í”„ë¼ì¸ ì‹œì‘ ì‹¤íŒ¨: %s\n", g_ffmpeg_pipeline->last_error().c_str());
            fflush(stdout);
            g_ffmpeg_pipeline.reset();
            CleanupWASAPI();
            CleanupDXGIDuplication();
            if (g_audio_thread.joinable()) g_audio_thread.join();
            g_is_recording = false;
            return;
        }
    } catch (const std::exception& e) {
        printf("[C++] âŒ FFmpeg íŒŒì´í”„ë¼ì¸ ì‹œì‘ ì¤‘ ì˜ˆì™¸ ë°œìƒ: %s\n", e.what());
        fflush(stdout);
        SetLastError(std::string("FFmpeg íŒŒì´í”„ë¼ì¸ ì‹œì‘ ì˜ˆì™¸: ") + e.what());
        g_ffmpeg_pipeline.reset();
        CleanupWASAPI();
        CleanupDXGIDuplication();
        if (g_audio_thread.joinable()) g_audio_thread.join();
        g_is_recording = false;
        return;
    } catch (...) {
        printf("[C++] âŒ FFmpeg íŒŒì´í”„ë¼ì¸ ì‹œì‘ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜ˆì™¸ ë°œìƒ\n");
        fflush(stdout);
        SetLastError("FFmpeg íŒŒì´í”„ë¼ì¸ ì‹œì‘ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜ˆì™¸ ë°œìƒ");
        g_ffmpeg_pipeline.reset();
        CleanupWASAPI();
        CleanupDXGIDuplication();
        if (g_audio_thread.joinable()) g_audio_thread.join();
        g_is_recording = false;
        return;
    }

    // ì¸ì½”ë” ìŠ¤ë ˆë“œ ì‹œì‘
    g_encoder_thread = std::thread(EncoderThreadFunc);

    printf("[C++] âœ… ëª¨ë“  ì´ˆê¸°í™” ì™„ë£Œ, ë…¹í™” ì‹œì‘\n");
    fflush(stdout);

    // ë©”ì¸ ìº¡ì²˜ ë£¨í”„
    int frame_count = 0;
    printf("[C++] í”„ë ˆì„ ìº¡ì²˜ ë£¨í”„ ì‹œì‘...\n");
    fflush(stdout);

    while (g_is_recording) {
        if (CaptureFrame()) {
            frame_count++;
            if (frame_count == 1) {
                printf("[C++] ğŸ¬ ì²« ë²ˆì§¸ í”„ë ˆì„ ìº¡ì²˜ ì„±ê³µ!\n");
                fflush(stdout);
            }
            if (frame_count % 24 == 0) {  // 1ì´ˆë§ˆë‹¤ ë¡œê·¸ (24fps ê¸°ì¤€)
                printf("[C++] ğŸ“Š ìº¡ì²˜ëœ í”„ë ˆì„: %d\n", frame_count);
                fflush(stdout);
            }
        } else {
            // ìº¡ì²˜ ì‹¤íŒ¨ ì‹œ ë£¨í”„ ì¢…ë£Œ
            printf("[C++] âŒ í”„ë ˆì„ ìº¡ì²˜ ì‹¤íŒ¨, ë£¨í”„ ì¢…ë£Œ (ì´ %d í”„ë ˆì„)\n", frame_count);
            fflush(stdout);
            g_is_recording = false;
            break;
        }
    }

    printf("[C++] ìº¡ì²˜ ë£¨í”„ ì¢…ë£Œ, ì´ %d í”„ë ˆì„ ìº¡ì²˜ë¨\n", frame_count);
    fflush(stdout);

    // ì¸ì½”ë” ìŠ¤ë ˆë“œ ì¢…ë£Œ ëŒ€ê¸°
    if (g_encoder_thread.joinable()) {
        printf("[C++] ì¸ì½”ë” ìŠ¤ë ˆë“œ ì¢…ë£Œ ëŒ€ê¸°...\n");
        fflush(stdout);
        g_encoder_thread.join();
    }

    // ì˜¤ë””ì˜¤ ìŠ¤ë ˆë“œ ì¢…ë£Œ ëŒ€ê¸°
    if (g_audio_thread.joinable()) {
        printf("[C++] ì˜¤ë””ì˜¤ ìŠ¤ë ˆë“œ ì¢…ë£Œ ëŒ€ê¸°...\n");
        fflush(stdout);
        g_audio_thread.join();
    }

    // ì •ë¦¬
    if (g_ffmpeg_pipeline) {
        g_ffmpeg_pipeline->Stop();
        g_ffmpeg_pipeline.reset();
    }
    CleanupWASAPI();
    CleanupDXGIDuplication();
    printf("[C++] ëª¨ë“  ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ\n");
    fflush(stdout);
}

// ========== C ì¸í„°í˜ì´ìŠ¤ êµ¬í˜„ (extern "C" ë§í¬) ==========

extern "C" {

// ë…¹í™” ì´ˆê¸°í™”
int32_t NativeRecorder_Initialize() {
    try {
        // COM ì´ˆê¸°í™” (ë©€í‹°ìŠ¤ë ˆë“œ ì•„íŒŒíŠ¸)
        HRESULT hr = CoInitializeEx(nullptr, COINIT_MULTITHREADED);
        if (FAILED(hr) && hr != RPC_E_CHANGED_MODE) {
            SetLastError("COM ì´ˆê¸°í™” ì‹¤íŒ¨");
            return -1;
        }
        g_com_initialized = true;

        // Direct3D11 ë””ë°”ì´ìŠ¤ ìƒì„±
        if (!CreateD3D11Device()) {
            SetLastError("D3D11 ë””ë°”ì´ìŠ¤ ìƒì„± ì‹¤íŒ¨");
            return -2;
        }

        SetLastError("");
        return 0;  // ì„±ê³µ
    } catch (const std::exception& e) {
        SetLastError(std::string("Initialize failed: ") + e.what());
        return -1;
    }
}

// ë…¹í™” ì‹œì‘
int32_t NativeRecorder_StartRecording(
    const char* output_path,
    int32_t width,
    int32_t height,
    int32_t fps
) {
    if (g_is_recording) {
        SetLastError("Already recording");
        return -2;
    }

    if (!output_path || strlen(output_path) == 0) {
        SetLastError("Invalid output path");
        return -3;
    }

    try {
        g_is_recording = true;

        // ìº¡ì²˜ ìŠ¤ë ˆë“œ ì‹œì‘
        g_capture_thread = std::thread(
            CaptureThreadFunc,
            std::string(output_path),
            width,
            height,
            fps
        );

        SetLastError("");
        return 0;  // ì„±ê³µ
    } catch (const std::exception& e) {
        g_is_recording = false;
        SetLastError(std::string("StartRecording failed: ") + e.what());
        return -1;
    }
}

// ë…¹í™” ì¤‘ì§€
int32_t NativeRecorder_StopRecording() {
    if (!g_is_recording) {
        SetLastError("Not recording");
        return -2;
    }

    try {
        g_is_recording = false;

        // ìº¡ì²˜ ìŠ¤ë ˆë“œ ì¢…ë£Œ ëŒ€ê¸°
        if (g_capture_thread.joinable()) {
            g_capture_thread.join();
        }

        SetLastError("");
        return 0;  // ì„±ê³µ
    } catch (const std::exception& e) {
        SetLastError(std::string("StopRecording failed: ") + e.what());
        return -1;
    }
}

// ë…¹í™” ì¤‘ ì—¬ë¶€ í™•ì¸
int32_t NativeRecorder_IsRecording() {
    return g_is_recording ? 1 : 0;
}

// ë¦¬ì†ŒìŠ¤ ì •ë¦¬
void NativeRecorder_Cleanup() {
    if (g_is_recording) {
        NativeRecorder_StopRecording();
    }

    // ì˜¤ë””ì˜¤ ìŠ¤ë ˆë“œ ì¢…ë£Œ ëŒ€ê¸°
    if (g_audio_thread.joinable()) {
        g_audio_thread.join();
    }

    if (g_ffmpeg_pipeline) {
        g_ffmpeg_pipeline->Stop();
        g_ffmpeg_pipeline.reset();
    }

    // WASAPI ë¦¬ì†ŒìŠ¤ ì •ë¦¬
    CleanupWASAPI();

    // DXGI Duplication ë¦¬ì†ŒìŠ¤ ì •ë¦¬
    CleanupDXGIDuplication();

    // Direct3D11 ë¦¬ì†ŒìŠ¤ ì •ë¦¬
    CleanupD3D11();

    // COM ì¢…ë£Œ
    if (g_com_initialized) {
        CoUninitialize();
        g_com_initialized = false;
    }
}

// ë§ˆì§€ë§‰ ì—ëŸ¬ ë©”ì‹œì§€ ê°€ì ¸ì˜¤ê¸°
const char* NativeRecorder_GetLastError() {
    std::lock_guard<std::mutex> lock(g_error_mutex);
    return g_last_error.c_str();
}

// ============================================================================
// Phase 3.1.1: ë…¹í™” ì§„í–‰ë¥  ì¡°íšŒ í•¨ìˆ˜ë“¤
// ============================================================================

// í˜„ì¬ê¹Œì§€ ì¸ì½”ë”©ëœ ë¹„ë””ì˜¤ í”„ë ˆì„ ìˆ˜ ê°€ì ¸ì˜¤ê¸°
int64_t NativeRecorder_GetVideoFrameCount() {
    return g_video_frame_count;
}

// í˜„ì¬ê¹Œì§€ ì¸ì½”ë”©ëœ ì˜¤ë””ì˜¤ ìƒ˜í”Œ ìˆ˜ ê°€ì ¸ì˜¤ê¸°
int64_t NativeRecorder_GetAudioSampleCount() {
    return g_audio_sample_count;
}

// ë…¹í™” ì‹œì‘ ì´í›„ ê²½ê³¼ ì‹œê°„ (ë°€ë¦¬ì´ˆ)
// ë…¹í™” ì¤‘ì´ ì•„ë‹ˆë©´ 0 ë°˜í™˜
int64_t NativeRecorder_GetElapsedTimeMs() {
    if (!g_is_recording) {
        return 0;
    }

    LARGE_INTEGER current_qpc;
    QueryPerformanceCounter(&current_qpc);

    // QPC ì¹´ìš´íŠ¸ ì°¨ì´ë¥¼ ë°€ë¦¬ì´ˆë¡œ ë³€í™˜
    int64_t elapsed_counts = current_qpc.QuadPart - g_recording_start_qpc.QuadPart;
    int64_t elapsed_ms = (elapsed_counts * 1000LL) / g_qpc_frequency.QuadPart;

    return elapsed_ms;
}

// ============================================================================
// Phase 3.1.2: ì˜¤ë””ì˜¤ ë ˆë²¨ ì¡°íšŒ í•¨ìˆ˜ë“¤
// ============================================================================

// í˜„ì¬ ì˜¤ë””ì˜¤ RMS ë ˆë²¨ ê°€ì ¸ì˜¤ê¸° (0.0 ~ 1.0)
// RMS (Root Mean Square)ëŠ” ì†Œë¦¬ì˜ í‰ê·  ì—ë„ˆì§€ë¥¼ ë‚˜íƒ€ëƒ„
float NativeRecorder_GetAudioLevel() {
    return g_current_audio_level.load();
}

// í˜„ì¬ ì˜¤ë””ì˜¤ Peak ë ˆë²¨ ê°€ì ¸ì˜¤ê¸° (0.0 ~ 1.0)
// PeakëŠ” ìµœëŒ€ ì§„í­ì„ ë‚˜íƒ€ëƒ„
float NativeRecorder_GetAudioPeakLevel() {
    return g_peak_audio_level.load();
}

}  // extern "C"
